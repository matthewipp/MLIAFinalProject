[22:08:25.470] Namespace(root_path='../Data/npzs', dataset='Synapse', list_dir='../lists/lists_Synapse', num_classes=2, max_iterations=30000, max_epochs=150, batch_size=24, n_gpu=1, deterministic=0, base_lr=0.01, img_size=224, seed=69420, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, is_pretrain=True, exp='TU_Synapse224')
[22:08:25.493] 2 iterations per epoch. 300 max iterations 
[22:09:25.033] Namespace(root_path='../Data/npzs', dataset='Synapse', list_dir='../lists/lists_Synapse', num_classes=2, max_iterations=30000, max_epochs=150, batch_size=24, n_gpu=1, deterministic=0, base_lr=0.01, img_size=224, seed=69420, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, is_pretrain=True, exp='TU_Synapse224')
[22:09:25.061] 2 iterations per epoch. 300 max iterations 
[22:17:58.534] Namespace(root_path='../Data/npzs', dataset='Synapse', list_dir='../lists/lists_Synapse', num_classes=2, max_iterations=30000, max_epochs=150, batch_size=24, n_gpu=1, deterministic=0, base_lr=0.01, img_size=224, seed=69420, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, is_pretrain=True, exp='TU_Synapse224')
[22:17:58.555] 2 iterations per epoch. 300 max iterations 
[22:18:12.534] iteration 1 : loss : 0.469510, loss_ce: 0.408815
[22:18:14.722] iteration 2 : loss : 0.451007, loss_ce: 0.377496
[22:18:16.695] iteration 3 : loss : 0.426962, loss_ce: 0.343012
[22:18:17.210] iteration 4 : loss : 0.403169, loss_ce: 0.301955
[22:18:19.198] iteration 5 : loss : 0.375431, loss_ce: 0.259786
[22:18:19.711] iteration 6 : loss : 0.354547, loss_ce: 0.219177
[22:18:22.301] iteration 7 : loss : 0.331869, loss_ce: 0.185178
[22:18:22.823] iteration 8 : loss : 0.312459, loss_ce: 0.154175
[22:18:24.823] iteration 9 : loss : 0.291028, loss_ce: 0.128416
[22:18:25.338] iteration 10 : loss : 0.277086, loss_ce: 0.108935
[22:18:27.356] iteration 11 : loss : 0.262752, loss_ce: 0.092806
[22:18:27.867] iteration 12 : loss : 0.251814, loss_ce: 0.076733
[22:18:29.876] iteration 13 : loss : 0.241359, loss_ce: 0.065446
[22:18:30.392] iteration 14 : loss : 0.229517, loss_ce: 0.057882
[22:18:32.382] iteration 15 : loss : 0.227028, loss_ce: 0.050995
[22:18:32.898] iteration 16 : loss : 0.220311, loss_ce: 0.047452
[22:18:34.914] iteration 17 : loss : 0.222997, loss_ce: 0.043023
[22:18:35.431] iteration 18 : loss : 0.218913, loss_ce: 0.038923
[22:23:59.746] Namespace(root_path='../Data/npzs', dataset='Synapse', list_dir='../lists/lists_Synapse', num_classes=2, max_iterations=30000, max_epochs=150, batch_size=24, n_gpu=1, deterministic=0, base_lr=0.01, img_size=224, seed=69420, n_skip=3, vit_name='R50-ViT-B_16', vit_patches_size=16, is_pretrain=True, exp='TU_Synapse224')
[22:23:59.774] 2 iterations per epoch. 300 max iterations 
[22:24:13.801] iteration 1 : loss : 0.467583, loss_ce: 0.404887
[22:24:15.257] iteration 2 : loss : 0.449490, loss_ce: 0.377856
[22:24:17.197] iteration 3 : loss : 0.428873, loss_ce: 0.344415
[22:24:17.484] iteration 4 : loss : 0.402910, loss_ce: 0.302178
[22:24:19.481] iteration 5 : loss : 0.378152, loss_ce: 0.259819
[22:24:19.763] iteration 6 : loss : 0.350133, loss_ce: 0.222315
[22:24:21.739] iteration 7 : loss : 0.332146, loss_ce: 0.185151
[22:24:22.019] iteration 8 : loss : 0.308741, loss_ce: 0.158257
[22:24:23.999] iteration 9 : loss : 0.288352, loss_ce: 0.131612
[22:24:24.273] iteration 10 : loss : 0.294507, loss_ce: 0.106232
[22:24:26.265] iteration 11 : loss : 0.266841, loss_ce: 0.094511
[22:24:26.544] iteration 12 : loss : 0.252312, loss_ce: 0.080997
[22:24:28.536] iteration 13 : loss : 0.251584, loss_ce: 0.067204
[22:24:28.810] iteration 14 : loss : 0.231553, loss_ce: 0.069537
[22:24:30.813] iteration 15 : loss : 0.232414, loss_ce: 0.051298
[22:24:31.100] iteration 16 : loss : 0.217417, loss_ce: 0.050664
[22:24:33.631] iteration 17 : loss : 0.218944, loss_ce: 0.047233
[22:24:33.912] iteration 18 : loss : 0.236811, loss_ce: 0.036348
[22:24:35.881] iteration 19 : loss : 0.218622, loss_ce: 0.036148
[22:24:36.156] iteration 20 : loss : 0.214351, loss_ce: 0.041555
[22:24:38.162] iteration 21 : loss : 0.220548, loss_ce: 0.037515
[22:24:38.440] iteration 22 : loss : 0.226110, loss_ce: 0.038031
[22:24:40.779] iteration 23 : loss : 0.213220, loss_ce: 0.035458
[22:24:41.060] iteration 24 : loss : 0.204209, loss_ce: 0.036043
[22:24:43.043] iteration 25 : loss : 0.206132, loss_ce: 0.033529
[22:24:43.314] iteration 26 : loss : 0.215891, loss_ce: 0.031426
[22:24:45.288] iteration 27 : loss : 0.203975, loss_ce: 0.032953
[22:24:45.563] iteration 28 : loss : 0.202604, loss_ce: 0.026349
[22:24:47.549] iteration 29 : loss : 0.206954, loss_ce: 0.028324
[22:24:47.824] iteration 30 : loss : 0.248527, loss_ce: 0.025203
[22:24:49.804] iteration 31 : loss : 0.194485, loss_ce: 0.031116
[22:24:50.080] iteration 32 : loss : 0.217861, loss_ce: 0.025552
[22:24:52.077] iteration 33 : loss : 0.198891, loss_ce: 0.024510
[22:24:52.353] iteration 34 : loss : 0.202941, loss_ce: 0.025654
[22:24:54.333] iteration 35 : loss : 0.186041, loss_ce: 0.029433
[22:24:54.612] iteration 36 : loss : 0.214092, loss_ce: 0.026062
[22:24:56.585] iteration 37 : loss : 0.187146, loss_ce: 0.021173
[22:24:56.861] iteration 38 : loss : 0.187623, loss_ce: 0.024738
[22:24:58.828] iteration 39 : loss : 0.182247, loss_ce: 0.024639
[22:24:59.103] iteration 40 : loss : 0.184150, loss_ce: 0.024209
[22:25:01.137] iteration 41 : loss : 0.185342, loss_ce: 0.025992
[22:25:01.421] iteration 42 : loss : 0.191424, loss_ce: 0.021923
[22:25:03.412] iteration 43 : loss : 0.180625, loss_ce: 0.023323
[22:25:03.690] iteration 44 : loss : 0.162186, loss_ce: 0.017190
[22:25:05.676] iteration 45 : loss : 0.182695, loss_ce: 0.020737
[22:25:05.954] iteration 46 : loss : 0.162991, loss_ce: 0.020257
[22:25:07.935] iteration 47 : loss : 0.177555, loss_ce: 0.022567
[22:25:08.210] iteration 48 : loss : 0.165001, loss_ce: 0.021612
[22:25:10.217] iteration 49 : loss : 0.174520, loss_ce: 0.021218
[22:25:10.498] iteration 50 : loss : 0.176639, loss_ce: 0.021582
[22:25:12.472] iteration 51 : loss : 0.181050, loss_ce: 0.021195
[22:25:12.753] iteration 52 : loss : 0.158212, loss_ce: 0.022083
[22:25:14.749] iteration 53 : loss : 0.176109, loss_ce: 0.020473
[22:25:15.028] iteration 54 : loss : 0.182204, loss_ce: 0.025417
[22:25:17.010] iteration 55 : loss : 0.172047, loss_ce: 0.023281
[22:25:17.291] iteration 56 : loss : 0.182357, loss_ce: 0.023113
[22:25:19.297] iteration 57 : loss : 0.170891, loss_ce: 0.022962
[22:25:19.573] iteration 58 : loss : 0.178948, loss_ce: 0.021747
[22:25:21.574] iteration 59 : loss : 0.172151, loss_ce: 0.020448
[22:25:21.851] iteration 60 : loss : 0.163602, loss_ce: 0.016687
[22:25:23.852] iteration 61 : loss : 0.171251, loss_ce: 0.017103
[22:25:24.130] iteration 62 : loss : 0.182144, loss_ce: 0.024275
[22:25:26.129] iteration 63 : loss : 0.170932, loss_ce: 0.022444
[22:25:26.411] iteration 64 : loss : 0.179643, loss_ce: 0.023544
[22:25:28.405] iteration 65 : loss : 0.175819, loss_ce: 0.023563
[22:25:28.688] iteration 66 : loss : 0.163160, loss_ce: 0.020659
[22:25:30.681] iteration 67 : loss : 0.172916, loss_ce: 0.020655
[22:25:30.966] iteration 68 : loss : 0.177088, loss_ce: 0.022427
[22:25:32.957] iteration 69 : loss : 0.171102, loss_ce: 0.020769
[22:25:33.233] iteration 70 : loss : 0.178182, loss_ce: 0.017123
[22:25:35.808] iteration 71 : loss : 0.171640, loss_ce: 0.020146
[22:25:36.085] iteration 72 : loss : 0.165805, loss_ce: 0.020007
[22:25:38.105] iteration 73 : loss : 0.170991, loss_ce: 0.021436
[22:25:38.387] iteration 74 : loss : 0.172076, loss_ce: 0.017065
[22:25:40.423] iteration 75 : loss : 0.169312, loss_ce: 0.020582
[22:25:40.707] iteration 76 : loss : 0.162838, loss_ce: 0.014676
[22:25:42.740] iteration 77 : loss : 0.175425, loss_ce: 0.018519
[22:25:43.023] iteration 78 : loss : 0.168914, loss_ce: 0.020693
[22:25:45.065] iteration 79 : loss : 0.167708, loss_ce: 0.017335
[22:25:45.347] iteration 80 : loss : 0.171680, loss_ce: 0.027901
[22:25:47.397] iteration 81 : loss : 0.170529, loss_ce: 0.022332
[22:25:47.677] iteration 82 : loss : 0.165632, loss_ce: 0.022858
[22:25:49.709] iteration 83 : loss : 0.168327, loss_ce: 0.022223
[22:25:49.989] iteration 84 : loss : 0.160759, loss_ce: 0.019177
[22:25:52.017] iteration 85 : loss : 0.172984, loss_ce: 0.019260
[22:25:52.298] iteration 86 : loss : 0.161366, loss_ce: 0.017925
[22:25:54.325] iteration 87 : loss : 0.167579, loss_ce: 0.018821
[22:25:54.607] iteration 88 : loss : 0.163073, loss_ce: 0.017879
[22:25:56.642] iteration 89 : loss : 0.166059, loss_ce: 0.020031
[22:25:56.927] iteration 90 : loss : 0.164832, loss_ce: 0.019562
[22:25:58.979] iteration 91 : loss : 0.165098, loss_ce: 0.020850
[22:25:59.263] iteration 92 : loss : 0.182447, loss_ce: 0.014667
[22:26:01.325] iteration 93 : loss : 0.167341, loss_ce: 0.016794
[22:26:01.605] iteration 94 : loss : 0.168497, loss_ce: 0.019109
[22:26:03.665] iteration 95 : loss : 0.167282, loss_ce: 0.016692
[22:26:03.945] iteration 96 : loss : 0.158233, loss_ce: 0.019326
[22:26:05.990] iteration 97 : loss : 0.164696, loss_ce: 0.022924
[22:26:06.270] iteration 98 : loss : 0.186377, loss_ce: 0.014634
[22:26:08.322] iteration 99 : loss : 0.175148, loss_ce: 0.021991
[22:26:08.606] iteration 100 : loss : 0.149290, loss_ce: 0.019760
[22:26:10.716] iteration 101 : loss : 0.167462, loss_ce: 0.018688
[22:26:11.000] iteration 102 : loss : 0.153468, loss_ce: 0.016052
[22:26:13.076] iteration 103 : loss : 0.166094, loss_ce: 0.017472
[22:26:13.353] iteration 104 : loss : 0.162227, loss_ce: 0.020075
[22:26:15.433] iteration 105 : loss : 0.163256, loss_ce: 0.019378
[22:26:15.716] iteration 106 : loss : 0.165617, loss_ce: 0.017415
[22:26:17.785] iteration 107 : loss : 0.165816, loss_ce: 0.020390
[22:26:18.075] iteration 108 : loss : 0.161468, loss_ce: 0.016101
[22:26:20.109] iteration 109 : loss : 0.168703, loss_ce: 0.016434
[22:26:20.396] iteration 110 : loss : 0.172725, loss_ce: 0.027517
[22:26:22.474] iteration 111 : loss : 0.159303, loss_ce: 0.018606
[22:26:22.764] iteration 112 : loss : 0.158488, loss_ce: 0.018853
[22:26:24.808] iteration 113 : loss : 0.161528, loss_ce: 0.020580
[22:26:25.087] iteration 114 : loss : 0.162068, loss_ce: 0.017519
[22:26:27.111] iteration 115 : loss : 0.162081, loss_ce: 0.016940
[22:26:27.388] iteration 116 : loss : 0.172713, loss_ce: 0.023122
[22:26:29.410] iteration 117 : loss : 0.159913, loss_ce: 0.017996
[22:26:29.697] iteration 118 : loss : 0.169721, loss_ce: 0.015411
[22:26:31.760] iteration 119 : loss : 0.158689, loss_ce: 0.019375
[22:26:32.050] iteration 120 : loss : 0.161313, loss_ce: 0.015452
[22:26:34.122] iteration 121 : loss : 0.159557, loss_ce: 0.016742
[22:26:34.403] iteration 122 : loss : 0.166298, loss_ce: 0.023682
[22:26:36.445] iteration 123 : loss : 0.159810, loss_ce: 0.016944
[22:26:36.916] iteration 124 : loss : 0.149989, loss_ce: 0.018521
[22:26:39.394] iteration 125 : loss : 0.159569, loss_ce: 0.019050
[22:26:39.686] iteration 126 : loss : 0.151119, loss_ce: 0.015674
[22:26:41.768] iteration 127 : loss : 0.158358, loss_ce: 0.019042
[22:26:42.050] iteration 128 : loss : 0.154801, loss_ce: 0.014450
[22:26:44.112] iteration 129 : loss : 0.159118, loss_ce: 0.015851
[22:26:44.392] iteration 130 : loss : 0.165094, loss_ce: 0.018796
[22:26:46.450] iteration 131 : loss : 0.157500, loss_ce: 0.017780
[22:26:46.738] iteration 132 : loss : 0.158621, loss_ce: 0.019009
[22:26:48.821] iteration 133 : loss : 0.157487, loss_ce: 0.020061
[22:26:49.109] iteration 134 : loss : 0.165952, loss_ce: 0.014468
[22:26:51.160] iteration 135 : loss : 0.152877, loss_ce: 0.016890
[22:26:51.448] iteration 136 : loss : 0.169128, loss_ce: 0.020619
[22:26:53.529] iteration 137 : loss : 0.155752, loss_ce: 0.015779
[22:26:53.811] iteration 138 : loss : 0.163057, loss_ce: 0.020085
[22:26:55.872] iteration 139 : loss : 0.157220, loss_ce: 0.017327
[22:26:56.153] iteration 140 : loss : 0.149532, loss_ce: 0.020216
[22:26:58.216] iteration 141 : loss : 0.156619, loss_ce: 0.018399
[22:26:58.494] iteration 142 : loss : 0.167020, loss_ce: 0.022585
[22:27:00.552] iteration 143 : loss : 0.158847, loss_ce: 0.017817
[22:27:00.833] iteration 144 : loss : 0.144842, loss_ce: 0.019161
[22:27:02.869] iteration 145 : loss : 0.157321, loss_ce: 0.015961
[22:27:03.148] iteration 146 : loss : 0.156415, loss_ce: 0.021688
[22:27:05.212] iteration 147 : loss : 0.156011, loss_ce: 0.018140
[22:27:05.503] iteration 148 : loss : 0.151748, loss_ce: 0.019058
[22:27:07.543] iteration 149 : loss : 0.153280, loss_ce: 0.018176
[22:27:07.824] iteration 150 : loss : 0.146699, loss_ce: 0.015492
[22:27:09.909] iteration 151 : loss : 0.153297, loss_ce: 0.014835
[22:27:10.201] iteration 152 : loss : 0.155648, loss_ce: 0.020419
[22:27:12.272] iteration 153 : loss : 0.151900, loss_ce: 0.015544
[22:27:12.554] iteration 154 : loss : 0.151147, loss_ce: 0.023155
[22:27:14.615] iteration 155 : loss : 0.153881, loss_ce: 0.018386
[22:27:14.896] iteration 156 : loss : 0.155831, loss_ce: 0.020973
[22:27:16.948] iteration 157 : loss : 0.151301, loss_ce: 0.018464
[22:27:17.233] iteration 158 : loss : 0.145238, loss_ce: 0.011087
[22:27:19.302] iteration 159 : loss : 0.157080, loss_ce: 0.015796
[22:27:19.581] iteration 160 : loss : 0.151478, loss_ce: 0.013277
[22:27:21.695] iteration 161 : loss : 0.151918, loss_ce: 0.013227
[22:27:21.981] iteration 162 : loss : 0.157045, loss_ce: 0.024737
[22:27:24.066] iteration 163 : loss : 0.154774, loss_ce: 0.020823
[22:27:24.343] iteration 164 : loss : 0.165386, loss_ce: 0.017346
[22:27:26.384] iteration 165 : loss : 0.157831, loss_ce: 0.022470
[22:27:26.665] iteration 166 : loss : 0.181522, loss_ce: 0.016615
[22:27:28.715] iteration 167 : loss : 0.149377, loss_ce: 0.015997
[22:27:28.998] iteration 168 : loss : 0.152628, loss_ce: 0.015298
[22:27:31.067] iteration 169 : loss : 0.156474, loss_ce: 0.016625
[22:27:31.348] iteration 170 : loss : 0.147107, loss_ce: 0.013950
[22:27:33.437] iteration 171 : loss : 0.149619, loss_ce: 0.015509
[22:27:33.716] iteration 172 : loss : 0.156156, loss_ce: 0.019235
[22:27:35.791] iteration 173 : loss : 0.149578, loss_ce: 0.017185
[22:27:36.075] iteration 174 : loss : 0.150608, loss_ce: 0.019038
[22:27:38.166] iteration 175 : loss : 0.145616, loss_ce: 0.016718
[22:27:38.448] iteration 176 : loss : 0.169491, loss_ce: 0.020214
[22:27:41.139] iteration 177 : loss : 0.152093, loss_ce: 0.016159
[22:27:41.425] iteration 178 : loss : 0.147417, loss_ce: 0.020627
[22:27:43.509] iteration 179 : loss : 0.152800, loss_ce: 0.017034
[22:27:43.789] iteration 180 : loss : 0.148920, loss_ce: 0.021190
[22:27:45.862] iteration 181 : loss : 0.150300, loss_ce: 0.017152
[22:27:46.138] iteration 182 : loss : 0.143178, loss_ce: 0.016358
[22:27:48.182] iteration 183 : loss : 0.143094, loss_ce: 0.016082
[22:27:48.461] iteration 184 : loss : 0.148429, loss_ce: 0.013195
[22:27:50.496] iteration 185 : loss : 0.144157, loss_ce: 0.012340
[22:27:50.772] iteration 186 : loss : 0.173968, loss_ce: 0.027067
[22:27:52.790] iteration 187 : loss : 0.152762, loss_ce: 0.017332
[22:27:53.075] iteration 188 : loss : 0.145388, loss_ce: 0.021942
[22:27:55.125] iteration 189 : loss : 0.162574, loss_ce: 0.018592
[22:27:55.405] iteration 190 : loss : 0.155923, loss_ce: 0.025887
[22:27:57.421] iteration 191 : loss : 0.149067, loss_ce: 0.018497
[22:27:57.699] iteration 192 : loss : 0.149367, loss_ce: 0.012500
[22:27:59.762] iteration 193 : loss : 0.147997, loss_ce: 0.015531
[22:28:00.048] iteration 194 : loss : 0.157051, loss_ce: 0.013638
[22:28:02.131] iteration 195 : loss : 0.145881, loss_ce: 0.014822
[22:28:02.421] iteration 196 : loss : 0.146759, loss_ce: 0.017625
[22:28:04.496] iteration 197 : loss : 0.154036, loss_ce: 0.016269
[22:28:04.777] iteration 198 : loss : 0.143480, loss_ce: 0.022442
[22:28:06.835] iteration 199 : loss : 0.147372, loss_ce: 0.018222
[22:28:07.115] iteration 200 : loss : 0.149191, loss_ce: 0.014494
[22:28:09.862] save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo150_bs24_224_s69420/epoch_99.pth
[22:28:11.369] iteration 201 : loss : 0.146399, loss_ce: 0.017367
[22:28:11.660] iteration 202 : loss : 0.153245, loss_ce: 0.009608
[22:28:13.745] iteration 203 : loss : 0.154803, loss_ce: 0.012976
[22:28:14.027] iteration 204 : loss : 0.154002, loss_ce: 0.018978
[22:28:16.034] iteration 205 : loss : 0.146840, loss_ce: 0.015145
[22:28:16.312] iteration 206 : loss : 0.141835, loss_ce: 0.016407
[22:28:18.371] iteration 207 : loss : 0.145575, loss_ce: 0.018377
[22:28:18.653] iteration 208 : loss : 0.162639, loss_ce: 0.017147
[22:28:20.713] iteration 209 : loss : 0.148397, loss_ce: 0.017128
[22:28:20.991] iteration 210 : loss : 0.141913, loss_ce: 0.017220
[22:28:23.037] iteration 211 : loss : 0.142221, loss_ce: 0.014444
[22:28:23.314] iteration 212 : loss : 0.149215, loss_ce: 0.017474
[22:28:25.360] iteration 213 : loss : 0.140409, loss_ce: 0.012385
[22:28:25.642] iteration 214 : loss : 0.154044, loss_ce: 0.021200
[22:28:27.678] iteration 215 : loss : 0.145621, loss_ce: 0.015861
[22:28:27.960] iteration 216 : loss : 0.138655, loss_ce: 0.020108
[22:28:30.022] iteration 217 : loss : 0.149124, loss_ce: 0.019540
[22:28:30.308] iteration 218 : loss : 0.144360, loss_ce: 0.015638
[22:28:32.370] iteration 219 : loss : 0.136921, loss_ce: 0.016205
[22:28:32.651] iteration 220 : loss : 0.153376, loss_ce: 0.012360
[22:28:34.757] iteration 221 : loss : 0.143126, loss_ce: 0.012585
[22:28:35.040] iteration 222 : loss : 0.153893, loss_ce: 0.019404
[22:28:37.131] iteration 223 : loss : 0.138386, loss_ce: 0.013537
[22:28:37.418] iteration 224 : loss : 0.139002, loss_ce: 0.019224
[22:28:39.491] iteration 225 : loss : 0.143611, loss_ce: 0.017194
[22:28:39.774] iteration 226 : loss : 0.147949, loss_ce: 0.017147
[22:28:41.858] iteration 227 : loss : 0.139838, loss_ce: 0.016849
[22:28:42.403] iteration 228 : loss : 0.138824, loss_ce: 0.013932
[22:28:44.874] iteration 229 : loss : 0.136550, loss_ce: 0.013854
[22:28:45.162] iteration 230 : loss : 0.150541, loss_ce: 0.015803
[22:28:47.249] iteration 231 : loss : 0.139012, loss_ce: 0.013700
[22:28:47.530] iteration 232 : loss : 0.155022, loss_ce: 0.016015
[22:28:49.602] iteration 233 : loss : 0.139624, loss_ce: 0.015993
[22:28:49.891] iteration 234 : loss : 0.137894, loss_ce: 0.016137
[22:28:51.960] iteration 235 : loss : 0.143376, loss_ce: 0.018009
[22:28:52.242] iteration 236 : loss : 0.132766, loss_ce: 0.012957
[22:28:54.299] iteration 237 : loss : 0.136574, loss_ce: 0.015658
[22:28:54.577] iteration 238 : loss : 0.142845, loss_ce: 0.011414
[22:28:56.641] iteration 239 : loss : 0.141890, loss_ce: 0.014144
[22:28:56.921] iteration 240 : loss : 0.136148, loss_ce: 0.011244
[22:28:58.964] iteration 241 : loss : 0.144117, loss_ce: 0.013252
[22:28:59.241] iteration 242 : loss : 0.130976, loss_ce: 0.015723
[22:29:01.275] iteration 243 : loss : 0.138865, loss_ce: 0.015838
[22:29:01.554] iteration 244 : loss : 0.137917, loss_ce: 0.012712
[22:29:03.595] iteration 245 : loss : 0.140005, loss_ce: 0.013992
[22:29:03.877] iteration 246 : loss : 0.141614, loss_ce: 0.021467
[22:29:05.911] iteration 247 : loss : 0.135076, loss_ce: 0.015946
[22:29:06.188] iteration 248 : loss : 0.150377, loss_ce: 0.011724
[22:29:08.219] iteration 249 : loss : 0.133532, loss_ce: 0.013778
[22:29:08.497] iteration 250 : loss : 0.134423, loss_ce: 0.014306
[22:29:10.559] iteration 251 : loss : 0.133435, loss_ce: 0.013655
[22:29:10.852] iteration 252 : loss : 0.139526, loss_ce: 0.012455
[22:29:12.917] iteration 253 : loss : 0.136242, loss_ce: 0.014882
[22:29:13.196] iteration 254 : loss : 0.130923, loss_ce: 0.011085
[22:29:15.277] iteration 255 : loss : 0.132651, loss_ce: 0.015570
[22:29:15.558] iteration 256 : loss : 0.153820, loss_ce: 0.008479
[22:29:17.644] iteration 257 : loss : 0.131852, loss_ce: 0.012999
[22:29:17.925] iteration 258 : loss : 0.134390, loss_ce: 0.014208
[22:29:20.009] iteration 259 : loss : 0.138422, loss_ce: 0.014346
[22:29:20.288] iteration 260 : loss : 0.128065, loss_ce: 0.009131
[22:29:22.405] iteration 261 : loss : 0.133586, loss_ce: 0.014055
[22:29:22.693] iteration 262 : loss : 0.131171, loss_ce: 0.010430
[22:29:24.796] iteration 263 : loss : 0.134332, loss_ce: 0.015916
[22:29:25.078] iteration 264 : loss : 0.152752, loss_ce: 0.009038
[22:29:27.193] iteration 265 : loss : 0.134484, loss_ce: 0.013632
[22:29:27.479] iteration 266 : loss : 0.130971, loss_ce: 0.013567
[22:29:29.590] iteration 267 : loss : 0.132264, loss_ce: 0.013367
[22:29:29.874] iteration 268 : loss : 0.129794, loss_ce: 0.011458
[22:29:32.003] iteration 269 : loss : 0.130506, loss_ce: 0.012277
[22:29:32.289] iteration 270 : loss : 0.135724, loss_ce: 0.017876
[22:29:34.383] iteration 271 : loss : 0.129171, loss_ce: 0.015563
[22:29:34.664] iteration 272 : loss : 0.178318, loss_ce: 0.012629
[22:29:36.742] iteration 273 : loss : 0.129815, loss_ce: 0.015362
[22:29:37.028] iteration 274 : loss : 0.127427, loss_ce: 0.011022
[22:29:39.077] iteration 275 : loss : 0.131549, loss_ce: 0.012545
[22:29:39.357] iteration 276 : loss : 0.131044, loss_ce: 0.015309
[22:29:41.419] iteration 277 : loss : 0.136572, loss_ce: 0.013662
[22:29:41.697] iteration 278 : loss : 0.124481, loss_ce: 0.009777
[22:29:43.769] iteration 279 : loss : 0.131167, loss_ce: 0.012948
[22:29:44.048] iteration 280 : loss : 0.121599, loss_ce: 0.015035
[22:29:46.699] iteration 281 : loss : 0.130810, loss_ce: 0.014402
[22:29:46.976] iteration 282 : loss : 0.126777, loss_ce: 0.013811
[22:29:49.065] iteration 283 : loss : 0.129048, loss_ce: 0.015225
[22:29:49.355] iteration 284 : loss : 0.149551, loss_ce: 0.011812
[22:29:51.413] iteration 285 : loss : 0.129313, loss_ce: 0.013276
[22:29:51.696] iteration 286 : loss : 0.123818, loss_ce: 0.012981
[22:29:53.792] iteration 287 : loss : 0.131683, loss_ce: 0.012690
[22:29:54.077] iteration 288 : loss : 0.117448, loss_ce: 0.012214
[22:29:56.155] iteration 289 : loss : 0.126919, loss_ce: 0.013251
[22:29:56.446] iteration 290 : loss : 0.146942, loss_ce: 0.011134
[22:29:58.510] iteration 291 : loss : 0.128399, loss_ce: 0.012991
[22:29:58.791] iteration 292 : loss : 0.127362, loss_ce: 0.011641
[22:30:00.830] iteration 293 : loss : 0.127564, loss_ce: 0.013794
[22:30:01.107] iteration 294 : loss : 0.129359, loss_ce: 0.010371
[22:30:03.140] iteration 295 : loss : 0.127690, loss_ce: 0.014134
[22:30:03.430] iteration 296 : loss : 0.128662, loss_ce: 0.010709
[22:30:05.487] iteration 297 : loss : 0.125931, loss_ce: 0.013803
[22:30:05.765] iteration 298 : loss : 0.128727, loss_ce: 0.011633
[22:30:07.826] iteration 299 : loss : 0.129752, loss_ce: 0.013159
[22:30:08.103] iteration 300 : loss : 0.117414, loss_ce: 0.013647
[22:30:10.821] save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo150_bs24_224_s69420/epoch_149.pth
[22:30:13.595] save model to ../model/TU_Synapse224/TU_pretrain_R50-ViT-B_16_skip3_epo150_bs24_224_s69420/epoch_149.pth
